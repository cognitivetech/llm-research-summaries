# Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges

Qian Niu, Junyu Liu, Ziqian Bi, Pohsun Feng, Benji Peng, Keyu Chen, Ming Li

https://arxiv.org/abs/2409.02387

## Contents
- [Abstract](#abstract)
- [I. Introduction](#i-introduction)
- [II. Comparison of LLMs and Human Cognitive Processes](#ii-comparison-of-llms-and-human-cognitive-processes)
- [III. Applications of LLMs in Cognitive Science](#iii-applications-of-llms-in-cognitive-science)
  - [A. LLMs as Cognitive Models](#a-llms-as-cognitive-models)
  - [B. Insights from LLMs for cognitive science](#b-insights-from-llms-for-cognitive-science)
- [IV. Limitations and Improvement of LLMs Capabilities](#iv-limitations-and-improvement-of-llms-capabilities)
- [V. Integration of LLMs with Cognitive Architectures](#v-integration-of-llms-with-cognitive-architectures)
- [VI. Discussion](#vi-discussion)

## Abstract
**Large Language Models (LLMs) and Cognitive Science: A Comprehensive Review**

**Exploring Intersections**:
- Explores similarities and differences between LLMs and human cognitive processes

**Evaluating LLM's Cognitive Abilities**:
- Analyses methods for evaluating LLMs' cognitive abilities
- Discusses their potential as cognitive models

**Applications of LLMs in Cognitive Fields**:
- Highlights insights gained for cognitive science research

**Cognitive Biases and Limitations of LLMs**:
- Assesses these aspects of LLMs
- Proposed methods for improving their performance

**Integration of LLMs with Cognitive Architectures**:
- Examines promising avenues for enhancing artificial intelligence (AI) capabilities

**Key Challenges and Future Research Directions**:
- Identifies challenges in aligning LLMs with human cognition
- Emphasizes the need for continued refinement of LLMs

**Review Provides a Balanced Perspective**:
- On the current state and future potential of LLMs in advancing our understanding of both artificial and human intelligence.

## I. Introduction

**Introduction**
- LLMs (Large Language Models) have sparked a revolution in AI, challenging our understanding of machine cognition and its relationship to human cognitive processes
- LLMs demonstrate increasingly sophisticated capabilities in language processing, reasoning, and problem-solving
- Cognitive scientists seek to unravel the mysteries of human cognition by exploring the intersection of LLMs and cognitive science

**Relationship between LLMs and Cognitive Science**
- Insights from cognitive science have informed the development and evaluation of LLMs
  - New architectures and training paradigms that mimic human cognitive processes
- Remarkable performance of LLMs on cognitive tasks has prompted researchers to reevaluate existing theories of cognition

**Review Aims**
- Provide a comprehensive overview of current research at the intersection of LLMs and cognitive science
- Explore similarities and differences between LLMs and human cognitive processes
- Examine methods for evaluating LLM's cognitive abilities, challenges, and opportunities
- Investigate potential of LLMs as cognitive models and insights into human cognition
- Address cognitive biases and limitations of LLMs, ongoing efforts to improve performance

**Impact and Future Research**
- Critically assess the relationship between LLMs and human cognition
- Identify key areas for future research
- Discuss challenges and opportunities in this dynamic area of study
- Deepen understanding of human cognition and inform the development of more sophisticated, ethical, and human-centric AI systems.

## II. Comparison of LLMs and Human Cognitive Processes

**Comparison of LLMs and Human Cognitive Processes**

**Similarities and Differences**:
- LLMs have demonstrated human-like capabilities in:
  - Language processing
  - Sensory judgments
  - Reasoning
- However, there are fundamental differences between LLMs and human cognitive processes:
  - Humans outperform LLMs in reasoning tasks, especially with out-of-distribution prompts
  - LLMs struggle to generalize beyond their training data and emulate basic statistical principles
  - LLMs excel at surface-level language processing but struggle with deeper, context-dependent understanding and reasoning
  - The memory properties of LLMs differ from human biological memory

**Methods for Evaluating LLMs' Cognitive Abilities**:
- Researchers use methods inspired by cognitive science and psychology to evaluate LLMs:
  - Adapting cognitive psychology experiments for LLMs (e.g., CogBench)
  - Comparing LLM representations with human brain activity using neuroimaging data (e.g., fMRI, MEG)
  - Adapting traditional psychological tests for LLMs (e.g., reasoning tasks, semantic illusions)
  - Studying LLMs' capacities and underlying abstractions using developmental psychology methods
- Multi-modal cognitive benchmarks like MulCogBench provide comprehensive evaluation tools for LLMs.

## III. Applications of LLMs in Cognitive Science

**III. Applications of LLMs in Cognitive Science** \n
- Use of LLMs in research expands avenues for human cognition study and AI development
- Examines role as cognitive models, theoretical insights, and applications across various domains
- Synthesizes recent research to offer comprehensive overview on current state and future potential of LLMs in advancing human cognition understanding.

### A. LLMs as Cognitive Models

**LLMs as Cognitive Models**

**Potential of LLMs**:
- Can be turned into accurate cognitive models through fine-tuning on psychological experiment data
- Often outperform traditional cognitive models in decision-making tasks
- Capture individual differences in behavior and generalize to new tasks after fine-tuning
- Potential to become generalist cognitive models representing a wide range of human cognitive processes

**Versatility of LLMs**:
- **Rational Meaning Construction**: Integrates neural language models with probabilistic models for rational inference
- Demonstrates LLMs' ability to generate context-sensitive translations and support commonsense reasoning
- **Capture Essential Aspects of Meaning**: Challenges skepticism about LLMs' ability to possess human-like concepts

**Language Processing**:
- Transformer-based ANN models can predict neural and behavioral responses in human language processing
- Predictive processing shapes language comprehension mechanisms in the brain

**Grammatical Language**:
- LLMs can produce human-like grammatical language without an innate grammar
- Provides valuable models for exploring statistical learning in language acquisition

**Emergent Cognitive Abilities**:
- LLMs can develop integrated cognitive skills like dynamical semantic operations, theory of mind, affordance recognition, and logical reasoning

**Empirical Evidence**:
- LLMs perform at human levels in various cognitive tasks like reasoning and problem-solving
- Supports associationism as a unifying theory of cognition

**Duality with Tulving's Theory of Memory**:
- Suggests consciousness may be an emergent ability based on the duality between LLMs and Tulving's theory of memory

**Caution in Interpreting Findings**:
- Fundamental differences in architecture and learning processes between LLMs and the human brain must be considered
- Further research is needed to fully understand capabilities and limitations of LLMs as cognitive models

### B. Insights from LLMs for cognitive science

**LLMs and Cognitive Science Research: Insights and Applications**

**Insights from LLMs for Cognitive Science**
- Veres [32]: LLMs challenge rule-based theories but do not necessarily provide deeper insights into language or cognition
- Shanahan [33]: Importance of understanding true nature and capabilities of LLMs to avoid anthropomorphism and ensure responsible use in research
- Blank [34]: Debate on whether LLMs can be considered computational models of human language processing, emphasizing the need for rigorous empirical investigation
- Grindrod [35]: LLMs as scientific models of E-languages (external languages), providing insights into the nature of language as a social entity
- Horton [36]: Potential use of LLMs as simulated economic agents to replicate behavioral economics experiments
- Connell and Lynott [37]: Evaluating cognitive plausibility of different types of language models, emphasizing importance of learning mechanisms, corpus size, and grounding in assessing relevance to human cognition
- Mitchell and Krakauer [38]: Advocating for an extended science of intelligence to explore diverse modes of cognition
- Buttrick [39]: Using LLMs to study cultural distinctions by analyzing statistical regularities in their training data
- Demszky et al. [40]: Reviewing potential of LLMs to transform psychology by enabling large-scale analysis and generation of language data

**LLMs in Specific Cognitive Fields**
- Causal Reasoning: Liu et al. [41]: Enhancing causal perspectives, fairness, and safety in LLMs; Kıcıman et al. [42]: Outperforming existing methods in generating causal arguments
- Lexical Semantics: Petersen and Potts [43]: Capturing sense distinctions and identifying new combinations using LLM representations
- Creative Writing: Chakrabarty et al. [44]: Assisting professional writers through empirical user study, revealing strengths and weaknesses of current models

**Conclusion**
- Significant potential of LLMs in cognitive science research across various domains (causal reasoning, lexical semantics, creative writing)
- Continued critical examination and empirical investigation needed to address challenges (interpretability, ethical considerations, overinterpretation of model capabilities)
- Interdisciplinary collaboration crucial for refining LLMs, developing more rigorous evaluation methods, and addressing ethical concerns
- Future holds promise for transformative insights into the nature of intelligence and bridging gaps between computational models and human cognition.

## IV. Limitations and Improvement of LLMs Capabilities

**Limitations and Improvement of LLMs**

**Cognitive Biases and Limitations**:
- Ullman [45]: LLMs fail on trivial alterations to Theory-of-Mind tasks, suggesting lack of robust Theory-of-Mind capabilities.
- Talboy and Fuller [46]: Identified multiple cognitive biases in LLMs similar to those found in human reasoning.
- Thorstad [47]: Advocated for cautious optimism about LLMs' performance while acknowledging genuine biases, particularly framing effects.
- Singh et al. [48]: Investigated the confidence-competence gap in LLMs, revealing instances of overconfidence and underconfidence reminiscent of the Dunning-Kruger effect.
- Marcus et al. [49]: Argued that LLMs currently lack deeper linguistic and cognitive understanding, leading to incomplete and biased representations of human language.
- Macmillan-Scott and Musolesi [50]: Evaluated seven LLMs using cognitive psychology tasks, finding that they display irrationality differently from humans and exhibit significant inconsistency in their responses.
- Jones and Steinhardt [51]: Presented a method inspired by human cognitive biases to systematically identify and test for qualitative errors in LLMs, uncovering predictable and high-impact errors.
- Smith et al. [52]: Proposed using the term "confabulation" instead of "hallucination" to more accurately describe inaccurate outputs of LLMs, emphasizing the importance of precise metaphorical language in understanding AI processes.

**Methods for Improving LLMs Performance**:
- Nguyen [53]: Introduced the bounded pragmatic speaker model to understand and improve language models by drawing parallels with human cognition and suggesting enhancements to reinforcement learning from human feedback (RLHF).
- Lv et al. [54]: Developed CogGPT, an LLM-driven agent with an iterative cognitive mechanism that outperforms existing methods in facilitating role-specific cognitive dynamics under continuous information flows.
- Prystawski et al. [55]: Demonstrated that using chain-of-thought prompts informed by probabilistic models can improve LLMs' ability to understand and paraphrase metaphors.
- Aw and Toneva [56]: Found that training language models to summarize narratives improves their alignment with human brain activity, indicating deeper language understanding.
- Du et al. [57]: Reviewed recent developments addressing shortcut learning and robustness challenges in LLMs, suggesting the combination of data-driven schemes with domain knowledge and the introduction of more inductive biases into model architectures.

## V. Integration of LLMs with Cognitive Architectures

**Integration of Language Models (LLMs) with Cognitive Architectures**

**Recent Research**:
- Explored various approaches to integrate LLMs with cognitive architectures
- Aims to enhance AI systems' capabilities

**Approaches for Integration**:
- **Modular**: Leverages the strengths of both LLMs and cognitive architectures while mitigating their weaknesses
- **Agency**: Theoretical grounding, empirical support
- **Neuro-Symbolic**: Theoretical grounding, empirical support

**Knowledge Extraction from LLMs by Cognitive Agents**:
- Kirk et al. [59] proposed a six-step process for knowledge extraction and integration into cognitive architectures

**Augmenting Cognitive Architectures with LLMs**:
- Joshi and Ustun [60]: Augmented Soar and Sigma with generative LLMs as prompt-able declarative memory
- González-Santamarta et al. [61]: Integrated LLMs into the MERLIN2 cognitive architecture for autonomous robots

**Benefits of Combining LLMs with Cognitive Architectures**:
- Zhu and Simmons [62]: Improved efficiency and fewer required tokens compared to using LLMs alone
- Nakos and Forbus [63]: Improvements in disambiguation and fact plausibility prediction for natural language understanding tasks
- Wray et al. [64]: Proposed a research strategy for integrating LLMs into cognitive agents to improve task learning and performance
- Zhou et al. [65]: Integrated LLMs with a cognitive memory mechanism to enhance user modeling and improve personalized search results

**Challenges**:
- Ensuring the accuracy and relevance of extracted knowledge
- Managing computational costs
- Addressing the limitations of both LLMs and cognitive architectures

**Future Research Directions**:
- Exploring more sophisticated integration methods
- Improving the efficiency of LLM-based reasoning
- Investigating the application of these integrated systems in various domains

## VI. Discussion

**Discussion:**
* Intersection of LLMs and cognitive science: exciting new frontier in AI, human cognition
* Significant progress made: comparing LLMs to human cognitive processes, developing methods for evaluating LLMs' cognitive abilities, exploring potential as cognitive models
* Similarities between LLMs and humans: language processing, reasoning (some aspects)
* Differences: reasoning capabilities (robustness, flexibility), functional linguistic competence
* Future research: enhancing generalization capabilities, improving performance in functional linguistic competence
* Potential of LLMs as cognitive models: gaining insights into human cognitive processes
* Caution needed: consider fundamental differences between LLMs and human brain

**Future Challenges:**
* Develop more sophisticated methods for aligning LLMs with human cognitive processes
	+ Integrate insights from cognitive science into architecture and training of LLMs
	+ Explore novel ways to evaluate and compare LLMs' performance with human cognition across a wider range of tasks
* Application of LLMs in specific cognitive fields: demonstrates potential contributions to research
	+ Continued refinement and specialization for specific domains
* Cognitive biases and limitations of LLMs: similarities to human reasoning, opportunities for new insights into nature and origins of biases in human cognition
* Integration of LLMs with cognitive architectures: leveraging strengths, mitigating weaknesses.

**Conclusion:**
* Exciting possibilities for advancing understanding of AI and human intelligence
* Significant challenges require careful consideration and further research
* Balanced perspective needed: acknowledging capabilities and limitations of LLMs.

